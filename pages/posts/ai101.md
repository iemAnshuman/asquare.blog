---
title: Artificial Intelligence 101
date: 2025-09-21
type: note
---

### Artificial Intelligence and It's applications

There isn't one universally accepted definition of AI. Think of Artificial Intelligence as the science of making machines that perform tasks that would normally require human intelligence.

It's applications include:

- Healthcare: Disease diagnosis, treatment, and prevention
- Finance: Fraud detection, algorithmic trading, portfolio management
- Transportation: Self-driving cars, traffic management, route optimization in google maps
- Personal Assistants: Device Integrated assistants like siri, alexa, google assistant
- Robotics: Household helpers, industrial automation, military robots
- Education: Personalized learning with adaptive learning algorithms, autograding

### so what does intelligence mean?

The field is often broken down into four major goals or schools of thought, organized along two dimensions: thinking vs. acting and humanly vs. rationally.

1. Thinking Humanly (The Cognitive Modeling Approach): This approach aims to build systems that think like humans. To do this, we would need to understand the actual workings of the human brain. This is the domain of Cognitive Science, which uses computational models from AI and experimental techniques from psychology to construct testable theories of the human mind.

2. Acting Humanly (The Turing Test Approach): This is the classic "imitation game" proposed by Alan Turing in 1950. A system passes the Turing Test if a human interrogator, after posing some written questions, cannot tell whether the written responses come from a person or a computer. This test focuses on behavior, not the underlying thought processes. While historically significant, it's not a central focus of AI research today, as it's more a test of deception than true intelligence.

3. Thinking Rationally (The "Laws of Thought" Approach): This approach is rooted in formal logic, dating back to Aristotle. The idea is to build systems that reason through syllogisms and logical deduction. For example, if we know "Socrates is a man" and "All men are mortal," a rational thinking system can deduce that "Socrates is mortal." The challenge is that the real world is messy and uncertain; not everything can be represented in clean, formal logic.

4. Acting Rationally (The Rational Agent Approach): This is the dominant approach in modern AI. It focuses on creating agents that act to achieve the best expected outcome. An agent doesn't need to think like a human; it just needs to do the right thing. For example, a self-driving car braking to avoid an accident is acting rationally, regardless of whether its internal "thought process" resembles a human driver's. This approach is more general and mathematically well-defined, as it allows us to build systems that solve problems, even if their methods are inhumanly fast or complex.

### Techniques of Artificial Intelligence

(for reading reference only)

- Searching: Brute force, heuristic search, A\* Search
- Knowledge Representation: Logic, Semantic networks, ontologies
- Reasoning: Deductive, inductive, abductive
- Machine Learning: Supervised, unsupervised, reinforcement learning
- Deep Learning: modeling neural networks
- Natural Language Processing: Understanding and generating human language

### Level of Models

A model is a representation of knowledge or patterns about the world that allows a machine to make predictions, decisions, or actions.

1. Artificial Narrow Intelligence: designed to perform a specific task, for example: stockfish for chess, chatgpt for natural language processing

2. Artificial General Intelligence: designed to perform any task that a human can, no examples yet.

3. Artificial SuperIntelligence: designed to perform any task. (surpasses human intelligence)

so how do we measure how effective an AI is on a particular task?

### Criteria of Success: How Do We Know It's Working?

The Turing Test provides a philosophical benchmark, but in practice, AI success is measured with concrete, task-specific metrics. We don't ask if a spam filter is "intelligent" in a human sense; we ask, "How accurately does it classify emails?", we try to quantify the effectiveness of the model to get a sense of how well it's performing rather than just juding using a human's intuition.

Success is defined by performance metrics. These vary by task:

- Classification: For tasks like spam detection or image recognition, we use metrics like Accuracy, Precision, Recall, and the F1-Score. These measure how many predictions were correct, how many of the positive predictions were truly positive, and how many of the true positives were found. [read more](https://developers.google.com/machine-learning/crash-course/classification/accuracy-precision-recall)

- Regression: For tasks that predict a continuous value (like forecasting house prices), we measure the error. A common metric is the Mean Squared Error (MSE), which penalizes larger errors more heavily

- Reinforcement Learning: For game-playing or robotic control, success is often measured by a reward signal—for instance, the total score achieved in a game or the time taken to complete a task.

The key takeaway is that AI performance isn't a vague, philosophical concept. It's a quantifiable measure of how well a system achieves its specified objective.

### Symbolic AI and Sub-Symbolic AI

#### Symbolic AI

Symbolic AI dominated the field from the 1950s to the 1980s. It's based on the hypothesis that intelligence can be achieved by manipulating symbols according to formal rules.

Knowledge Representation and Logic: the core idea is to represent human knowledge in a formal language, like First-Order Logic. We define objects, properties, and relations, and use logical rules to reason about them. This is the foundation of expert systems, which were popular in the 80s for tasks like medical diagnosis. They contained a knowledge base of expert rules and an inference engine to derive new conclusions.

Now, If you can represent a problem in terms of a state space (all possible configurations), then solving the problem becomes a matter of searching for a path from the initial state to a goal state. This is fundamental to everything from route planning in GPS to solving a Rubik's Cube.

- Uninformed Search: These algorithms have no information about the goal's location. They systematically explore the state space.

Breadth-First Search (BFS): Explores all neighbors of a node before moving to the next level. Guaranteed to find the shallowest solution.

Depth-First Search (DFS): Explores as far down one path as possible before backtracking. More memory-efficient but can get lost in infinite paths.

- Informed (Heuristic) Search: These algorithms use a heuristic—an educated guess or rule of thumb—to estimate the distance to the goal. This dramatically speeds up the search.

Greedy Best-First Search: Always expands the node that appears to be closest to the goal. It's fast but can be misled by a bad heuristic.

A* Search: The gold standard. It combines the cost to reach the current node, g(n), with the estimated cost to get from the current node to the goal, h(n). It seeks to minimize f(n)=g(n)+h(n). A* is guaranteed to find the optimal solution if the heuristic h(n) never overestimates the true cost.

#### Sub-Symbolic AI

Symbolic AI struggles with the messiness and uncertainty of the real world. How do you write down logical rules for identifying a cat in a photo? The sub-symbolic approach, dominated by Machine Learning (ML), takes a different path: it learns the rules from data. Instead of hand-crafting rules, we provide a model with a vast number of examples and let it learn the underlying patterns.

Machine Learning Paradigms

- Supervised Learning: This is the most common form of ML. The model is trained on a labeled dataset, where each data point has a known outcome or "label." The model's job is to learn the mapping from input to output.

Classification: The output is a discrete category (e.g., spam or not spam, cat or dog).

Regression: The output is a continuous value (e.g., predicting the price of a house).

- Unsupervised Learning: Here, the model is given unlabeled data and must find hidden structures or patterns on its own.

Clustering: Grouping similar data points together (e.g., segmenting customers based on purchasing behavior).

Dimensionality Reduction: Simplifying data by reducing the number of variables while preserving important information.

- Reinforcement Learning (RL): This paradigm is inspired by behavioral psychology. An agent learns by interacting with an environment. It receives rewards for good actions and penalties for bad ones. Over many trials, the agent learns a policy—a strategy for choosing actions that maximize its cumulative reward. This is the technique behind AI systems that master games like Go (AlphaGo) and control robots.

* Note: Symbolic AI are called "white box" models because their decision-making process is transparent and interpretable by humans while Sub-Symbolic AI are called "black box" models because they are opaque and difficult to understand.

## The Rational Agent

An agent is anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators. It is rational if it acts to maximize the expected value of a performance measure, given the evidence provided by its perceptual history.

#### The PEAS framework

- Performance Measure
- Enviroment
- Actuators
- Sensors

example:
|Agent Type|Performance Measure|Environment|Actuators|Sensors|
|---|---|---|---|---|
|**Self-Driving Car**|Safety, speed, legality, comfort, efficiency|Roads, traffic, pedestrians, weather|Steering, accelerator, brake, signals|Cameras, LiDAR, GPS, sonar, speedometer|
|**Spam Filter**|Minimizing false positives and false negatives|User's email account, mail servers|Mark as spam, move to folder|Incoming email text and metadata|
|**Medical Diagnosis System**|Patient health, minimized cost, correct diagnosis|Patient, hospital, staff|Questions, tests, treatments|Patient symptoms, test results, patient answers|

#### Properties of Enviroments

- Fully vs Partially Observable
- Deterministic vs Stochastic
- Episodic vs Sequential
- Static vs Dynamic
- Discrete vs Continuous
- Single Agent vs Multi Agent

--> brainstorm this

#### Agent Architecture

1. Simple Reflex Agents: select actions based on the current percept, ignoring the rest of the percept history.

2. Model-Based Reflex Agents: To handle partial observability, an agent needs to maintain an internal model of the world. It tracks how the world evolves and how its own actions affect the world. This allows it to make decisions based on an unperceived state.

It chooses an action based on a set of pre-programmed condition-action rules. The key difference from a Simple Reflex Agent is what the "condition" is matched against.

    A Simple Reflex Agent matches the condition against the current sensor data (IF car_in_front_brakes THEN brake).

    A Model-Based Agent matches the condition against its internal model of the world (IF car_in_front_brakes AND my_internal_model_says_road_is_wet THEN brake_gently).

3. Goal-Based Reflex Agents: Knowing about the world isn't enough; the agent needs a goal to aim for. These agents consider future actions and choose the one that will achieve their goal. Search and planning are key activities for goal-based agents. The agent might ask, "Which sequence of actions will get me from City A to City B?"

4. Utility-Based Agents: Sometimes there are multiple paths to the goal, or multiple goals. A utility function maps a state to a real number, which describes the associated degree of "happiness" or desirability. A rational utility-based agent chooses the action that maximizes the expected utility. This is useful when goals are conflicting (e.g., speed vs. safety in a self-driving car).

#### A learning Agent

A learning agent can be divided into four conceptual components:

Learning Element: This is responsible for making improvements. It uses feedback from the critic to modify the performance element.

Performance Element: This is what we have been calling the "agent" so far. It takes in percepts and decides on actions.

Critic: This component provides feedback. It looks at how the agent is doing with respect to a fixed performance standard and tells the learning element how the performance element should be modified. This feedback could be a reward signal in reinforcement learning.

Problem Generator: This component is responsible for suggesting actions that will lead to new and informative experiences. It encourages exploration, preventing the agent from getting stuck in a rut.[more with diagram](https://www.simform.com/blog/types-of-ai-agents/)

### AI in real world

(for reading reference only)

#### Advantages

1. Automation and Efficiency: AI can perform complex, repetitive tasks 24/7 without fatigue, freeing up humans for more creative and strategic work.

2. Scale and Speed: AI can analyze petabytes of data in minutes, a task that would be impossible for humans. This allows us to find patterns in everything from genomic data to astronomical surveys.

3. Accuracy and Precision: In well-defined tasks, AI can surpass human accuracy, reducing errors in critical applications like medical diagnosis and manufacturing.

4. Personalization: AI enables services to be tailored to individual users on a massive scale, from personalized learning plans to targeted advertising.

#### Disadvantages

1. Data Dependency: Most modern AI is data-hungry. The performance of a model is highly dependent on the quality and quantity of its training data. "Garbage in, garbage out" is the rule.

2. Bias and Fairness: AI models learn from data, and if that data reflects existing societal biases (e.g., gender or racial bias in hiring data), the model will learn and often amplify those biases.

3. Lack of Common Sense: AI systems have a very narrow understanding of the world. An AI that is a grandmaster at chess has no concept of what a chess piece is, why humans play games, or that it shouldn't be put in a glass of water. It lacks the general, common-sense reasoning that humans take for granted.

4. The "Black Box" Problem: As mentioned, the decisions of complex models like deep neural networks can be opaque. This is a huge problem in high-stakes domains like finance and medicine, where we need to understand why a decision was made.

5. Ethical Concerns: The rise of AI brings a host of difficult ethical questions: job displacement due to automation, privacy concerns from mass data collection, the potential for autonomous weapons, and the spread of AI-generated misinformation ("deepfakes").
