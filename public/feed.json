{
  "version": "https://jsonfeed.org/version/1",
  "title": "Anshuman Agrawal",
  "home_page_url": "https://asquare.blog/",
  "feed_url": "https://asquare.blog/feed.json",
  "description": "Notes, projects, and research logs",
  "icon": "https://asquare.blog/avatar.png",
  "author": {
    "name": "Anshuman Agrawal",
    "url": "https://asquare.blog"
  },
  "items": [
    {
      "content_html": "<p>abara ka dabra</p>\n",
      "url": "https://asquare.blog/posts/my-post",
      "title": "Blog",
      "date_modified": "2025-09-22T16:25:01.712Z",
      "author": {
        "name": "Anshuman Agrawal",
        "url": "https://asquare.blog"
      }
    },
    {
      "content_html": "<h3>Artificial Intelligence and It's applications</h3>\n<p>There isn't one universally accepted definition of AI. Think of Artificial Intelligence as the science of making machines that perform tasks that would normally require human intelligence.</p>\n<p>It's applications include:</p>\n<ul>\n<li>Healthcare: Disease diagnosis, treatment, and prevention</li>\n<li>Finance: Fraud detection, algorithmic trading, portfolio management</li>\n<li>Transportation: Self-driving cars, traffic management, route optimization in google maps</li>\n<li>Personal Assistants: Device Integrated assistants like siri, alexa, google assistant</li>\n<li>Robotics: Household helpers, industrial automation, military robots</li>\n<li>Education: Personalized learning with adaptive learning algorithms, autograding</li>\n</ul>\n<h3>so what does intelligence mean?</h3>\n<p>The field is often broken down into four major goals or schools of thought, organized along two dimensions: thinking vs. acting and humanly vs. rationally.</p>\n<ol>\n<li>\n<p>Thinking Humanly (The Cognitive Modeling Approach): This approach aims to build systems that think like humans. To do this, we would need to understand the actual workings of the human brain. This is the domain of Cognitive Science, which uses computational models from AI and experimental techniques from psychology to construct testable theories of the human mind.</p>\n</li>\n<li>\n<p>Acting Humanly (The Turing Test Approach): This is the classic &quot;imitation game&quot; proposed by Alan Turing in 1950. A system passes the Turing Test if a human interrogator, after posing some written questions, cannot tell whether the written responses come from a person or a computer. This test focuses on behavior, not the underlying thought processes. While historically significant, it's not a central focus of AI research today, as it's more a test of deception than true intelligence.</p>\n</li>\n<li>\n<p>Thinking Rationally (The &quot;Laws of Thought&quot; Approach): This approach is rooted in formal logic, dating back to Aristotle. The idea is to build systems that reason through syllogisms and logical deduction. For example, if we know &quot;Socrates is a man&quot; and &quot;All men are mortal,&quot; a rational thinking system can deduce that &quot;Socrates is mortal.&quot; The challenge is that the real world is messy and uncertain; not everything can be represented in clean, formal logic.</p>\n</li>\n<li>\n<p>Acting Rationally (The Rational Agent Approach): This is the dominant approach in modern AI. It focuses on creating agents that act to achieve the best expected outcome. An agent doesn't need to think like a human; it just needs to do the right thing. For example, a self-driving car braking to avoid an accident is acting rationally, regardless of whether its internal &quot;thought process&quot; resembles a human driver's. This approach is more general and mathematically well-defined, as it allows us to build systems that solve problems, even if their methods are inhumanly fast or complex.</p>\n</li>\n</ol>\n<h3>Techniques of Artificial Intelligence</h3>\n<p>(for reading reference only)</p>\n<ul>\n<li>Searching: Brute force, heuristic search, A* Search</li>\n<li>Knowledge Representation: Logic, Semantic networks, ontologies</li>\n<li>Reasoning: Deductive, inductive, abductive</li>\n<li>Machine Learning: Supervised, unsupervised, reinforcement learning</li>\n<li>Deep Learning: modeling neural networks</li>\n<li>Natural Language Processing: Understanding and generating human language</li>\n</ul>\n<h3>Level of Models</h3>\n<p>A model is a representation of knowledge or patterns about the world that allows a machine to make predictions, decisions, or actions.</p>\n<ol>\n<li>\n<p>Artificial Narrow Intelligence: designed to perform a specific task, for example: stockfish for chess, chatgpt for natural language processing</p>\n</li>\n<li>\n<p>Artificial General Intelligence: designed to perform any task that a human can, no examples yet.</p>\n</li>\n<li>\n<p>Artificial SuperIntelligence: designed to perform any task. (surpasses human intelligence)</p>\n</li>\n</ol>\n<p>so how do we measure how effective an AI is on a particular task?</p>\n<h3>Criteria of Success: How Do We Know It's Working?</h3>\n<p>The Turing Test provides a philosophical benchmark, but in practice, AI success is measured with concrete, task-specific metrics. We don't ask if a spam filter is &quot;intelligent&quot; in a human sense; we ask, &quot;How accurately does it classify emails?&quot;, we try to quantify the effectiveness of the model to get a sense of how well it's performing rather than just juding using a human's intuition.</p>\n<p>Success is defined by performance metrics. These vary by task:</p>\n<ul>\n<li>\n<p>Classification: For tasks like spam detection or image recognition, we use metrics like Accuracy, Precision, Recall, and the F1-Score. These measure how many predictions were correct, how many of the positive predictions were truly positive, and how many of the true positives were found. <a href=\"https://developers.google.com/machine-learning/crash-course/classification/accuracy-precision-recall\">read more</a></p>\n</li>\n<li>\n<p>Regression: For tasks that predict a continuous value (like forecasting house prices), we measure the error. A common metric is the Mean Squared Error (MSE), which penalizes larger errors more heavily</p>\n</li>\n<li>\n<p>Reinforcement Learning: For game-playing or robotic control, success is often measured by a reward signal—for instance, the total score achieved in a game or the time taken to complete a task.</p>\n</li>\n</ul>\n<p>The key takeaway is that AI performance isn't a vague, philosophical concept. It's a quantifiable measure of how well a system achieves its specified objective.</p>\n<h3>Symbolic AI and Sub-Symbolic AI</h3>\n<h4>Symbolic AI</h4>\n<p>Symbolic AI dominated the field from the 1950s to the 1980s. It's based on the hypothesis that intelligence can be achieved by manipulating symbols according to formal rules.</p>\n<p>Knowledge Representation and Logic: the core idea is to represent human knowledge in a formal language, like First-Order Logic. We define objects, properties, and relations, and use logical rules to reason about them. This is the foundation of expert systems, which were popular in the 80s for tasks like medical diagnosis. They contained a knowledge base of expert rules and an inference engine to derive new conclusions.</p>\n<p>Now, If you can represent a problem in terms of a state space (all possible configurations), then solving the problem becomes a matter of searching for a path from the initial state to a goal state. This is fundamental to everything from route planning in GPS to solving a Rubik's Cube.</p>\n<ul>\n<li>Uninformed Search: These algorithms have no information about the goal's location. They systematically explore the state space.</li>\n</ul>\n<p>Breadth-First Search (BFS): Explores all neighbors of a node before moving to the next level. Guaranteed to find the shallowest solution.</p>\n<p>Depth-First Search (DFS): Explores as far down one path as possible before backtracking. More memory-efficient but can get lost in infinite paths.</p>\n<ul>\n<li>Informed (Heuristic) Search: These algorithms use a heuristic—an educated guess or rule of thumb—to estimate the distance to the goal. This dramatically speeds up the search.</li>\n</ul>\n<p>Greedy Best-First Search: Always expands the node that appears to be closest to the goal. It's fast but can be misled by a bad heuristic.</p>\n<p>A* Search: The gold standard. It combines the cost to reach the current node, g(n), with the estimated cost to get from the current node to the goal, h(n). It seeks to minimize f(n)=g(n)+h(n). A* is guaranteed to find the optimal solution if the heuristic h(n) never overestimates the true cost.</p>\n<h4>Sub-Symbolic AI</h4>\n<p>Symbolic AI struggles with the messiness and uncertainty of the real world. How do you write down logical rules for identifying a cat in a photo? The sub-symbolic approach, dominated by Machine Learning (ML), takes a different path: it learns the rules from data. Instead of hand-crafting rules, we provide a model with a vast number of examples and let it learn the underlying patterns.</p>\n<p>Machine Learning Paradigms</p>\n<ul>\n<li>Supervised Learning: This is the most common form of ML. The model is trained on a labeled dataset, where each data point has a known outcome or &quot;label.&quot; The model's job is to learn the mapping from input to output.</li>\n</ul>\n<p>Classification: The output is a discrete category (e.g., spam or not spam, cat or dog).</p>\n<p>Regression: The output is a continuous value (e.g., predicting the price of a house).</p>\n<ul>\n<li>Unsupervised Learning: Here, the model is given unlabeled data and must find hidden structures or patterns on its own.</li>\n</ul>\n<p>Clustering: Grouping similar data points together (e.g., segmenting customers based on purchasing behavior).</p>\n<p>Dimensionality Reduction: Simplifying data by reducing the number of variables while preserving important information.</p>\n<ul>\n<li>Reinforcement Learning (RL): This paradigm is inspired by behavioral psychology. An agent learns by interacting with an environment. It receives rewards for good actions and penalties for bad ones. Over many trials, the agent learns a policy—a strategy for choosing actions that maximize its cumulative reward. This is the technique behind AI systems that master games like Go (AlphaGo) and control robots.</li>\n</ul>\n<ul>\n<li>Note: Symbolic AI are called &quot;white box&quot; models because their decision-making process is transparent and interpretable by humans while Sub-Symbolic AI are called &quot;black box&quot; models because they are opaque and difficult to understand.</li>\n</ul>\n<h2>The Rational Agent</h2>\n<p>An agent is anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators. It is rational if it acts to maximize the expected value of a performance measure, given the evidence provided by its perceptual history.</p>\n<h4>The PEAS framework</h4>\n<ul>\n<li>Performance Measure</li>\n<li>Enviroment</li>\n<li>Actuators</li>\n<li>Sensors</li>\n</ul>\n<p>example:</p>\n<table>\n<thead>\n<tr>\n<th>Agent Type</th>\n<th>Performance Measure</th>\n<th>Environment</th>\n<th>Actuators</th>\n<th>Sensors</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Self-Driving Car</strong></td>\n<td>Safety, speed, legality, comfort, efficiency</td>\n<td>Roads, traffic, pedestrians, weather</td>\n<td>Steering, accelerator, brake, signals</td>\n<td>Cameras, LiDAR, GPS, sonar, speedometer</td>\n</tr>\n<tr>\n<td><strong>Spam Filter</strong></td>\n<td>Minimizing false positives and false negatives</td>\n<td>User's email account, mail servers</td>\n<td>Mark as spam, move to folder</td>\n<td>Incoming email text and metadata</td>\n</tr>\n<tr>\n<td><strong>Medical Diagnosis System</strong></td>\n<td>Patient health, minimized cost, correct diagnosis</td>\n<td>Patient, hospital, staff</td>\n<td>Questions, tests, treatments</td>\n<td>Patient symptoms, test results, patient answers</td>\n</tr>\n</tbody>\n</table>\n<h4>Properties of Enviroments</h4>\n<ul>\n<li>Fully vs Partially Observable</li>\n<li>Deterministic vs Stochastic</li>\n<li>Episodic vs Sequential</li>\n<li>Static vs Dynamic</li>\n<li>Discrete vs Continuous</li>\n<li>Single Agent vs Multi Agent</li>\n</ul>\n<p>--&gt; brainstorm this</p>\n<h4>Agent Architecture</h4>\n<ol>\n<li>\n<p>Simple Reflex Agents: select actions based on the current percept, ignoring the rest of the percept history.</p>\n</li>\n<li>\n<p>Model-Based Reflex Agents: To handle partial observability, an agent needs to maintain an internal model of the world. It tracks how the world evolves and how its own actions affect the world. This allows it to make decisions based on an unperceived state.</p>\n</li>\n</ol>\n<p>It chooses an action based on a set of pre-programmed condition-action rules. The key difference from a Simple Reflex Agent is what the &quot;condition&quot; is matched against.</p>\n<pre><code>A Simple Reflex Agent matches the condition against the current sensor data (IF car_in_front_brakes THEN brake).\n\nA Model-Based Agent matches the condition against its internal model of the world (IF car_in_front_brakes AND my_internal_model_says_road_is_wet THEN brake_gently).\n</code></pre>\n<ol start=\"3\">\n<li>\n<p>Goal-Based Reflex Agents: Knowing about the world isn't enough; the agent needs a goal to aim for. These agents consider future actions and choose the one that will achieve their goal. Search and planning are key activities for goal-based agents. The agent might ask, &quot;Which sequence of actions will get me from City A to City B?&quot;</p>\n</li>\n<li>\n<p>Utility-Based Agents: Sometimes there are multiple paths to the goal, or multiple goals. A utility function maps a state to a real number, which describes the associated degree of &quot;happiness&quot; or desirability. A rational utility-based agent chooses the action that maximizes the expected utility. This is useful when goals are conflicting (e.g., speed vs. safety in a self-driving car).</p>\n</li>\n</ol>\n<h4>A learning Agent</h4>\n<p>A learning agent can be divided into four conceptual components:</p>\n<p>Learning Element: This is responsible for making improvements. It uses feedback from the critic to modify the performance element.</p>\n<p>Performance Element: This is what we have been calling the &quot;agent&quot; so far. It takes in percepts and decides on actions.</p>\n<p>Critic: This component provides feedback. It looks at how the agent is doing with respect to a fixed performance standard and tells the learning element how the performance element should be modified. This feedback could be a reward signal in reinforcement learning.</p>\n<p>Problem Generator: This component is responsible for suggesting actions that will lead to new and informative experiences. It encourages exploration, preventing the agent from getting stuck in a rut.<a href=\"https://www.simform.com/blog/types-of-ai-agents/\">more with diagram</a></p>\n<h3>AI in real world</h3>\n<p>(for reading reference only)</p>\n<h4>Advantages</h4>\n<ol>\n<li>\n<p>Automation and Efficiency: AI can perform complex, repetitive tasks 24/7 without fatigue, freeing up humans for more creative and strategic work.</p>\n</li>\n<li>\n<p>Scale and Speed: AI can analyze petabytes of data in minutes, a task that would be impossible for humans. This allows us to find patterns in everything from genomic data to astronomical surveys.</p>\n</li>\n<li>\n<p>Accuracy and Precision: In well-defined tasks, AI can surpass human accuracy, reducing errors in critical applications like medical diagnosis and manufacturing.</p>\n</li>\n<li>\n<p>Personalization: AI enables services to be tailored to individual users on a massive scale, from personalized learning plans to targeted advertising.</p>\n</li>\n</ol>\n<h4>Disadvantages</h4>\n<ol>\n<li>\n<p>Data Dependency: Most modern AI is data-hungry. The performance of a model is highly dependent on the quality and quantity of its training data. &quot;Garbage in, garbage out&quot; is the rule.</p>\n</li>\n<li>\n<p>Bias and Fairness: AI models learn from data, and if that data reflects existing societal biases (e.g., gender or racial bias in hiring data), the model will learn and often amplify those biases.</p>\n</li>\n<li>\n<p>Lack of Common Sense: AI systems have a very narrow understanding of the world. An AI that is a grandmaster at chess has no concept of what a chess piece is, why humans play games, or that it shouldn't be put in a glass of water. It lacks the general, common-sense reasoning that humans take for granted.</p>\n</li>\n<li>\n<p>The &quot;Black Box&quot; Problem: As mentioned, the decisions of complex models like deep neural networks can be opaque. This is a huge problem in high-stakes domains like finance and medicine, where we need to understand why a decision was made.</p>\n</li>\n<li>\n<p>Ethical Concerns: The rise of AI brings a host of difficult ethical questions: job displacement due to automation, privacy concerns from mass data collection, the potential for autonomous weapons, and the spread of AI-generated misinformation (&quot;deepfakes&quot;).</p>\n</li>\n</ol>\n",
      "url": "https://asquare.blog/posts/ai101",
      "title": "Artificial Intelligence 101",
      "date_modified": "2025-09-21T00:00:00.000Z",
      "author": {
        "name": "Anshuman Agrawal",
        "url": "https://asquare.blog"
      }
    },
    {
      "content_html": "<h3>AI 102 in Action: The Case of the Martian Biosignature 🤖🪐</h3>\n<p>In our last post, we built the theoretical engine for a reasoning machine. Now, let's put that engine to the test with a complex, real-world scenario.</p>\n<p>Imagine the Curiosity rover on Mars. It's not just a vehicle; it's a robotic scientist with a <strong>Knowledge Base (KB)</strong> of scientific facts. It just drilled a rock sample and now needs to determine if that sample contains evidence of life, based on its pre-programmed knowledge.</p>\n<p>This is not a task for simple pattern matching; it requires a chain of logical deduction. Let's see how the rover uses Resolution and Unification to make a new discovery.</p>\n<hr>\n<h3>The Scenario</h3>\n<ul>\n<li><strong>Goal:</strong> The rover, <code>Curiosity</code>, needs to prove that a sample, <code>RockA</code>, contains evidence of ancient life.</li>\n<li><strong>Query:</strong> <code>EvidenceOfLife(RockA)</code></li>\n</ul>\n<hr>\n<h3>1. The Knowledge Base (KB) in Predicate Logic</h3>\n<p>The rover has the following facts and rules programmed into its memory.</p>\n<p><strong>Facts:</strong></p>\n<ol>\n<li>Curiosity is a rover: <code>Rover(Curiosity)</code></li>\n<li>RockA is a sample: <code>Sample(RockA)</code></li>\n<li>Curiosity drilled RockA: <code>Drilled(Curiosity, RockA)</code></li>\n<li>RockA contains methane: <code>Contains(RockA, Methane)</code></li>\n<li>Methane is an organic molecule: <code>Organic(Methane)</code></li>\n</ol>\n<p><strong>Rules (General Scientific Knowledge):</strong> 6. Any sample that contains an organic molecule is considered a biosignature.<br>\n<code>∀x ∀y (Sample(x) ∧ Contains(x, y) ∧ Organic(y)) ⇒ Biosignature(x)</code> 7. If a sample is a biosignature, it is considered to have evidence of ancient life.<br>\n<code>∀x (Sample(x) ∧ Biosignature(x)) ⇒ EvidenceOfLife(x)</code></p>\n<hr>\n<h3>2. The Proof: Step-by-Step Automated Reasoning</h3>\n<p>The rover's task is to prove <code>EvidenceOfLife(RockA)</code> is true given its KB. It will use proof by contradiction.</p>\n<h4>Step 2.1: Convert the KB to Clause Form (CNF)</h4>\n<p>First, every sentence must be converted into a standard clause.</p>\n<ul>\n<li><strong>C1:</strong> <code>Rover(Curiosity)</code></li>\n<li><strong>C2:</strong> <code>Sample(RockA)</code></li>\n<li><strong>C3:</strong> <code>Drilled(Curiosity, RockA)</code></li>\n<li><strong>C4:</strong> <code>Contains(RockA, Methane)</code></li>\n<li><strong>C5:</strong> <code>Organic(Methane)</code></li>\n<li><strong>C6:</strong> <code>¬Sample(x) ∨ ¬Contains(x, y) ∨ ¬Organic(y) ∨ Biosignature(x)</code></li>\n<li><strong>C7:</strong> <code>¬Sample(x) ∨ ¬Biosignature(x) ∨ EvidenceOfLife(x)</code></li>\n</ul>\n<p><em>(Note: The fact <code>Drilled(Curiosity, RockA)</code> isn't strictly necessary for this specific proof, but a real-world KB would contain many related facts.)</em></p>\n<h4>Step 2.2: Negate the Goal</h4>\n<p>To begin the proof by contradiction, we assert the opposite of what we want to prove and add it to our set of clauses.</p>\n<ul>\n<li><strong>C8:</strong> <code>¬EvidenceOfLife(RockA)</code></li>\n</ul>\n<p>Now, the stage is set. The rover will apply the Resolution algorithm repeatedly, hoping to derive the <strong>empty clause ()</strong>, which signifies a contradiction.</p>\n<h4>Step 2.3: The Resolution Process 🔬</h4>\n<p>Let's follow the rover's logical steps. It will combine clauses that contain complementary literals, using <strong>Unification</strong> to match variables.</p>\n<p><strong>Resolution 1: Seeking evidence</strong></p>\n<ul>\n<li>The rover starts with its negated goal (<strong>C8</strong>) and looks for a clause to resolve it with. Clause <strong>C7</strong> contains <code>EvidenceOfLife(x)</code>.</li>\n<li><strong>Clauses:</strong>\n<ul>\n<li><code>¬Sample(x) ∨ ¬Biosignature(x) ∨ EvidenceOfLife(x)</code> (C7)</li>\n<li><code>¬EvidenceOfLife(RockA)</code> (C8)</li>\n</ul>\n</li>\n<li>The literals <code>EvidenceOfLife(x)</code> and <code>¬EvidenceOfLife(RockA)</code> can be made complementary.</li>\n<li><strong>Unification:</strong> The algorithm finds the Most General Unifier (MGU) <code>{x / RockA}</code>.</li>\n<li><strong>Result (C9):</strong> Applying the substitution and resolving the clauses leaves us with a new clause: <code>¬Sample(RockA) ∨ ¬Biosignature(RockA)</code></li>\n</ul>\n<p><strong>Resolution 2: What makes a biosignature?</strong></p>\n<ul>\n<li>The new clause <strong>C9</strong> contains <code>¬Biosignature(RockA)</code>. The rover finds Clause <strong>C6</strong>, which contains <code>Biosignature(x)</code>.</li>\n<li><strong>Clauses:</strong>\n<ul>\n<li><code>¬Sample(x) ∨ ¬Contains(x, y) ∨ ¬Organic(y) ∨ Biosignature(x)</code> (C6)</li>\n<li><code>¬Sample(RockA) ∨ ¬Biosignature(RockA)</code> (C9)</li>\n</ul>\n</li>\n<li><strong>Unification:</strong> To match <code>Biosignature(x)</code> and <code>¬Biosignature(RockA)</code>, the MGU is <code>{x / RockA}</code>.</li>\n<li><strong>Result (C10):</strong> We apply the substitution to both clauses and combine them, removing the <code>Biosignature</code> literals. Note that <code>¬Sample(RockA)</code> appears twice, but we only need to list it once.<br>\n<code>¬Sample(RockA) ∨ ¬Contains(RockA, y) ∨ ¬Organic(y)</code></li>\n</ul>\n<p><strong>Resolution 3: Checking the sample's contents</strong></p>\n<ul>\n<li>Clause <strong>C10</strong> contains <code>¬Contains(RockA, y)</code>. The rover's KB has a fact about what <code>RockA</code> contains in <strong>C4</strong>.</li>\n<li><strong>Clauses:</strong>\n<ul>\n<li><code>¬Sample(RockA) ∨ ¬Contains(RockA, y) ∨ ¬Organic(y)</code> (C10)</li>\n<li><code>Contains(RockA, Methane)</code> (C4)</li>\n</ul>\n</li>\n<li><strong>Unification:</strong> To match <code>¬Contains(RockA, y)</code> and <code>Contains(RockA, Methane)</code>, the MGU is <code>{y / Methane}</code>.</li>\n<li><strong>Result (C11):</strong> <code>¬Sample(RockA) ∨ ¬Organic(Methane)</code></li>\n</ul>\n<p><strong>Resolution 4: Confirming the sample</strong></p>\n<ul>\n<li>Clause <strong>C11</strong> has two negative literals. The rover can resolve <code>¬Sample(RockA)</code> with the simple fact in <strong>C2</strong>.</li>\n<li><strong>Clauses:</strong>\n<ul>\n<li><code>¬Sample(RockA) ∨ ¬Organic(Methane)</code> (C11)</li>\n<li><code>Sample(RockA)</code> (C2)</li>\n</ul>\n</li>\n<li><strong>Unification:</strong> No variables, this is a direct match.</li>\n<li><strong>Result (C12):</strong> <code>¬Organic(Methane)</code></li>\n</ul>\n<p><strong>Resolution 5: The Final Contradiction</strong></p>\n<ul>\n<li>The rover is now left with a single literal in clause <strong>C12</strong>. It checks its KB and finds the direct opposite in <strong>C5</strong>.</li>\n<li><strong>Clauses:</strong>\n<ul>\n<li><code>¬Organic(Methane)</code> (C12)</li>\n<li><code>Organic(Methane)</code> (C5)</li>\n</ul>\n</li>\n<li><strong>Result:</strong> <strong>The Empty Clause ()</strong></li>\n</ul>\n<hr>\n<h3>3. Conclusion: Discovery Made!</h3>\n<p>The rover has successfully derived the empty clause. This is a definitive logical contradiction. This proves that the initial assumption—that <code>RockA</code> did <em>not</em> have evidence of life—must be false.</p>\n<p>Therefore, the rover has logically proven that <strong><code>EvidenceOfLife(RockA)</code> is true.</strong> It can now confidently transmit this new, derived knowledge back to mission control, having made a discovery not by seeing it directly, but by reasoning from the facts and rules it already knew.</p>\n<p>This example, while simplified, shows the immense power of symbolic reasoning. By representing knowledge in a formal language and applying a single, powerful inference rule, an AI can navigate complex webs of facts to deduce new, non-obvious truths about its world.</p>\n",
      "url": "https://asquare.blog/posts/ai102.5",
      "title": "Artificial Intelligence 102.5",
      "date_modified": "2025-09-21T00:00:00.000Z",
      "author": {
        "name": "Anshuman Agrawal",
        "url": "https://asquare.blog"
      }
    },
    {
      "content_html": "<h2>Propositional Logic (PL)</h2>\n<p>The simplest form of logic is <strong>Propositional Logic</strong>. It's a formal system built around <strong>propositions</strong>, which are declarative sentences that can be either <strong>true</strong> or <strong>false</strong>, but not both.</p>\n<ul>\n<li><code>&quot;It is raining.&quot;</code> (This can be true or false)</li>\n<li><code>&quot;The battery is full.&quot;</code> (This can be true or false)</li>\n<li><code>&quot;2 + 2 = 4&quot;</code> (This is always true, so it's a valid proposition)</li>\n</ul>\n<p>To build meaningful statements, we combine these symbols using a set of logical connectives.</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">Connective</th>\n<th style=\"text-align:left\">Symbol</th>\n<th style=\"text-align:left\">Meaning</th>\n<th style=\"text-align:left\">Example</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><strong>Negation</strong></td>\n<td style=\"text-align:left\">$¬$</td>\n<td style=\"text-align:left\">NOT</td>\n<td style=\"text-align:left\"><code>¬P</code> (&quot;It is <strong>not</strong> raining.&quot;)</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Conjunction</strong></td>\n<td style=\"text-align:left\">$∧$</td>\n<td style=\"text-align:left\">AND</td>\n<td style=\"text-align:left\"><code>P ∧ Q</code> (&quot;It is raining <strong>and</strong> it is cloudy.&quot;)</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Disjunction</strong></td>\n<td style=\"text-align:left\">$∨$</td>\n<td style=\"text-align:left\">OR</td>\n<td style=\"text-align:left\"><code>P ∨ Q</code> (&quot;It is raining <strong>or</strong> it is cloudy.&quot;)</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Implication</strong></td>\n<td style=\"text-align:left\">$⇒$</td>\n<td style=\"text-align:left\">Implies (If... then...)</td>\n<td style=\"text-align:left\"><code>P ⇒ Q</code> (&quot;<strong>If</strong> it is raining, <strong>then</strong> it is cloudy.&quot;)</td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><strong>Biconditional</strong></td>\n<td style=\"text-align:left\">$⇔$</td>\n<td style=\"text-align:left\">If and only if</td>\n<td style=\"text-align:left\"><code>P ⇔ Q</code> (&quot;It is raining <strong>if and only if</strong> it is cloudy.&quot;)</td>\n</tr>\n</tbody>\n</table>\n<h3>Syntax and Semantics</h3>\n<p>Difference: Syntax is the set of rules for a language's grammar and structure, ensuring that expressions are correctly formed. Semantics, on the other hand, focuses on the meaning of those expressions, interpreting what they actually convey</p>\n<p>The <strong>semantics</strong>, or meaning, of these connectives are defined by <strong>truth tables</strong>. These tables show the truth value of a complex sentence for every possible combination of truth values of its simple components. Here is the crucial truth table for implication ($⇒$):</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">P</th>\n<th style=\"text-align:center\">Q</th>\n<th style=\"text-align:center\">P ⇒ Q</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">F</td>\n<td style=\"text-align:center\">F</td>\n<td style=\"text-align:center\">T</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">F</td>\n<td style=\"text-align:center\">T</td>\n<td style=\"text-align:center\">T</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">T</td>\n<td style=\"text-align:center\">F</td>\n<td style=\"text-align:center\">F</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">T</td>\n<td style=\"text-align:center\">T</td>\n<td style=\"text-align:center\">T</td>\n</tr>\n</tbody>\n</table>\n<h3>The Problem with Propositional Logic</h3>\n<p>Propositional logic is great, but it's fundamentally limited. It can't describe the world at a fine-grained level. Consider this famous argument:</p>\n<ol>\n<li>All humans are mortal.</li>\n<li>Socrates is a human.</li>\n<li>Therefore, Socrates is mortal.</li>\n</ol>\n<p>In propositional logic, we'd have to assign this to symbols:</p>\n<ul>\n<li>P = &quot;All humans are mortal.&quot;</li>\n<li>Q = &quot;Socrates is a human.&quot;</li>\n<li>R = &quot;Socrates is mortal.&quot;</li>\n</ul>\n<p>There is no way within the rules of PL to connect P, Q, and R to derive the conclusion. The logic doesn't understand that &quot;Socrates&quot; is a specific instance of a &quot;human&quot; or that the property &quot;mortal&quot; applies to all humans. We need a richer language.</p>\n<hr>\n<h2>Predicate Logic</h2>\n<p><strong>Predicate Logic</strong>, also known as <strong>First-Order Logic (FOL)</strong>, extends propositional logic with more expressive components. It allows us to talk about <strong>objects</strong>, their <strong>properties</strong>, and the <strong>relations</strong> between them.</p>\n<p>Here are its new building blocks:</p>\n<ul>\n<li><strong>Objects:</strong> Refer to specific things in the world (e.g., <code>Socrates</code>, <code>Cat</code>, <code>House</code>).</li>\n<li><strong>Predicates:</strong> Represent properties of objects or relations between them. A predicate is like a function that returns true or false. Examples:\n<ul>\n<li><code>Human(Socrates)</code> - A property: &quot;Socrates is a human.&quot;</li>\n<li><code>Brother(John, Richard)</code> - A relation: &quot;John is the brother of Richard.&quot;</li>\n</ul>\n</li>\n<li><strong>Quantifiers:</strong> These are symbols that let us talk about groups of objects.\n<ul>\n<li><strong>Universal Quantifier (∀):</strong> Means &quot;For all...&quot; or &quot;For every...&quot;. It makes a statement about every object in the universe.\n<blockquote>\n<p><code>∀x Human(x) ⇒ Mortal(x)</code><br>\n(Reads: &quot;For every object x, if x is a human, then x is mortal.&quot;)</p>\n</blockquote>\n</li>\n<li><strong>Existential Quantifier (∃):</strong> Means &quot;There exists...&quot; or &quot;For some...&quot;. It makes a statement about at least one object.\n<blockquote>\n<p><code>∃x Cat(x) ∧ Likes(x, Fish)</code><br>\n(Reads: &quot;There exists an object x such that x is a cat and x likes fish.&quot;)</p>\n</blockquote>\n</li>\n</ul>\n</li>\n</ul>\n<p>Now, with Predicate Logic, our Socrates argument is simple and logically sound. We can represent our knowledge and reason with it effectively.</p>\n<hr>\n<h2>Resolution</h2>\n<p>Okay, so we have a powerful language to store knowledge. But how does an AI <em>use</em> this knowledge to prove new things? We could define dozens of small inference rules (like Modus Ponens), but that's inefficient for a computer.</p>\n<p>We need a single, powerful inference algorithm that is <strong>complete</strong> (meaning it can prove any provable statement). That algorithm is <strong>Resolution</strong>.</p>\n<p>Resolution is a method for proving theorems by contradiction. The basic strategy is:</p>\n<ol>\n<li>Assume the <strong>opposite</strong> of what you want to prove.</li>\n<li>Show that this assumption, when combined with your existing knowledge, leads to an undeniable contradiction.</li>\n<li>Conclude that because your assumption led to a contradiction, it must be false. Therefore, the thing you originally wanted to prove must be true.</li>\n</ol>\n<h3>Prerequisite: Clause Form</h3>\n<p>Resolution requires all our logical sentences to be in a standard format called <strong>Clause Form</strong> or <strong>Conjunctive Normal Form (CNF)</strong>. A sentence is in CNF if it's a set of <strong>clauses</strong> connected by ANDs, where each clause is a set of <strong>literals</strong> connected by ORs.</p>\n<ul>\n<li>A <strong>literal</strong> is an atomic proposition (like <code>P</code>) or its negation (<code>¬P</code>).</li>\n<li>A <strong>clause</strong> is a disjunction of literals (e.g., <code>(¬Human(x) ∨ Mortal(x))</code>).</li>\n</ul>\n<p>Any sentence in propositional or predicate logic can be converted into CNF through a standard procedure. For our Socrates example, the knowledge becomes:</p>\n<ol>\n<li><code>∀x Human(x) ⇒ Mortal(x)</code> converts to the clause <code>(¬Human(x) ∨ Mortal(x))</code>.</li>\n<li><code>Human(Socrates)</code> is already the clause <code>(Human(Socrates))</code>.</li>\n</ol>\n<h3>Resolution in Propositional Logic</h3>\n<p>The resolution rule is beautifully simple. If you have two clauses that contain a complementary literal (e.g., <code>P</code> and <code>¬P</code>), you can combine them and cancel out that pair.</p>\n<p>For example, consider these two clauses:</p>\n<ol>\n<li><code>(Cloudy ∨ Raining)</code></li>\n<li><code>(¬Cloudy ∨ Wet_Grass)</code></li>\n</ol>\n<p>Intuitively, we know that it's either cloudy or it isn't.</p>\n<ul>\n<li>If <code>Cloudy</code> is <strong>false</strong>, then from clause 1, <code>Raining</code> must be true.</li>\n<li>If <code>Cloudy</code> is <strong>true</strong>, then from clause 2, <code>Wet_Grass</code> must be true.<br>\nSince <code>Cloudy</code> must be one or the other, we can conclude that <strong><code>(Raining ∨ Wet_Grass)</code></strong> must be true. This new clause is the <strong>resolvent</strong>.</li>\n</ul>\n<h3>Resolution in Predicate Logic &amp; The Unification Algorithm</h3>\n<p>In predicate logic, things get tricky because of variables. You can't resolve <code>(¬Human(x) ∨ Mortal(x))</code> with <code>(Human(Socrates))</code> because <code>x</code> and <code>Socrates</code> are not an exact complementary match.</p>\n<p>This is where <strong>Unification</strong> comes in.</p>\n<p><strong>Unification</strong> is an algorithm for finding a <strong>substitution</strong> that makes two different logical expressions look identical. A substitution is a mapping of variables to terms.</p>\n<p>Let's say we want to unify:</p>\n<ul>\n<li><code>Knows(John, x)</code></li>\n<li><code>Knows(y, MotherOf(y))</code></li>\n</ul>\n<p>The unification algorithm finds the <strong>Most General Unifier (MGU)</strong>, which is the substitution that makes the expressions identical while being as general as possible. The MGU here would be <code>{y / John, x / MotherOf(John)}</code>. Applying this substitution gives us the identical expression <code>Knows(John, MotherOf(John))</code>.</p>\n<h3>Putting It All Together: A Full Example</h3>\n<p>Let's use Resolution with Unification to formally prove that Socrates is mortal.</p>\n<p><strong>1. Knowledge Base (KB) in Clause Form:</strong></p>\n<ul>\n<li>Clause 1: <code>(¬Human(x) ∨ Mortal(x))</code></li>\n<li>Clause 2: <code>(Human(Socrates))</code></li>\n</ul>\n<p><strong>2. Goal to Prove:</strong> <code>Mortal(Socrates)</code></p>\n<p><strong>3. Proof by Contradiction:</strong></p>\n<ul>\n<li><strong>Negate the goal:</strong> <code>¬Mortal(Socrates)</code>. This becomes our third clause.</li>\n<li><strong>KB now contains:</strong>\n<ol>\n<li><code>(¬Human(x) ∨ Mortal(x))</code></li>\n<li><code>(Human(Socrates))</code></li>\n<li><code>(¬Mortal(Socrates))</code></li>\n</ol>\n</li>\n</ul>\n<p><strong>4. Apply Resolution:</strong></p>\n<ul>\n<li>\n<p><strong>Step A:</strong> Let's resolve Clause 1 and Clause 3.</p>\n<ul>\n<li>We want to match the literals <code>Mortal(x)</code> and <code>¬Mortal(Socrates)</code>.</li>\n<li>Unification finds the MGU: <code>{x / Socrates}</code>.</li>\n<li>Apply this substitution to Clause 1, which becomes <code>(¬Human(Socrates) ∨ Mortal(Socrates))</code>.</li>\n<li>Now, resolve this with <code>(¬Mortal(Socrates))</code>. The complementary literals <code>Mortal(Socrates)</code> and <code>¬Mortal(Socrates)</code> cancel out.</li>\n<li><strong>Our new resolvent is: <code>(¬Human(Socrates))</code></strong>.</li>\n</ul>\n</li>\n<li>\n<p><strong>Step B:</strong> Our KB now effectively contains:</p>\n<ol>\n<li><code>(Human(Socrates))</code> (from the original KB)</li>\n<li><code>(¬Human(Socrates))</code> (the new clause we just derived)</li>\n</ol>\n</li>\n<li>\n<p><strong>Step C:</strong> Resolve these two clauses. They are a direct contradiction. When you resolve <code>P</code> and <code>¬P</code>, you are left with nothing. This is called the <strong>empty clause ()</strong>.</p>\n</li>\n</ul>\n<p><strong>5. Conclusion:</strong><br>\nWe have derived the empty clause! This signifies a contradiction. Our initial assumption—that <code>¬Mortal(Socrates)</code> was true—must be false. Therefore, the original goal, <strong><code>Mortal(Socrates)</code></strong>, is proven to be <strong>true</strong>.</p>\n<hr>\n",
      "url": "https://asquare.blog/posts/ai102",
      "title": "Artificial Intelligence 102",
      "date_modified": "2025-09-21T00:00:00.000Z",
      "author": {
        "name": "Anshuman Agrawal",
        "url": "https://asquare.blog"
      }
    },
    {
      "content_html": "<h3>Part 1: The Dataset - Agricultural Pest Detection</h3>\n<p>Imagine we're building a system for a smart farming drone. The drone's camera measures physical characteristics of insects it finds, and our goal is to classify them as either a &quot;Beneficial Insect&quot; (like a bee, label <code>0</code>) or a &quot;Harmful Pest&quot; (like a locust, label <code>1</code>).</p>\n<p>Here is our raw data for six insects the drone has scanned:</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">SampleID</th>\n<th style=\"text-align:left\">Size (mm)</th>\n<th style=\"text-align:left\">Weight (mg)</th>\n<th style=\"text-align:left\">Wing_Span (mm)</th>\n<th style=\"text-align:left\">Type (Label)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">1</td>\n<td style=\"text-align:left\">10</td>\n<td style=\"text-align:left\">150</td>\n<td style=\"text-align:left\">22</td>\n<td style=\"text-align:left\">1 (Harmful)</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">2</td>\n<td style=\"text-align:left\">5</td>\n<td style=\"text-align:left\">50</td>\n<td style=\"text-align:left\">10</td>\n<td style=\"text-align:left\">0 (Beneficial)</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">3</td>\n<td style=\"text-align:left\">12</td>\n<td style=\"text-align:left\">160</td>\n<td style=\"text-align:left\">25</td>\n<td style=\"text-align:left\">1 (Harmful)</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">4</td>\n<td style=\"text-align:left\">7</td>\n<td style=\"text-align:left\">80</td>\n<td style=\"text-align:left\">15</td>\n<td style=\"text-align:left\">0 (Beneficial)</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">5</td>\n<td style=\"text-align:left\">15</td>\n<td style=\"text-align:left\">200</td>\n<td style=\"text-align:left\">30</td>\n<td style=\"text-align:left\">1 (Harmful)</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">6</td>\n<td style=\"text-align:left\">6</td>\n<td style=\"text-align:left\">65</td>\n<td style=\"text-align:left\">12</td>\n<td style=\"text-align:left\">0 (Beneficial)</td>\n</tr>\n</tbody>\n</table>\n<p>Looking at this raw data, we can immediately spot a problem. The <code>Weight (mg)</code> feature has values that are roughly 10-20 times larger than the <code>Size (mm)</code> feature. An algorithm that uses distance calculations (like k-Nearest Neighbors) would be completely dominated by the <code>Weight</code> feature, practically ignoring the others. We need to fix this.</p>\n<hr>\n<h3>Part 2: Data Preprocessing - Standardization in Action</h3>\n<p>To solve the scaling issue, we'll apply <strong>Standardization (Z-score Scaling)</strong>, which will give each feature a mean of 0 and a standard deviation of 1.</p>\n<p>The formula is: $x_{std} = \\frac{x - \\mu}{\\sigma}$</p>\n<p><strong>Step 1: Calculate Mean ($μ$) and Standard Deviation ($σ$) for each feature.</strong></p>\n<ul>\n<li><strong>Size (mm):</strong>\n<ul>\n<li>$μ_{size} = (10+5+12+7+15+6) / 6 = 9.17$</li>\n<li>$σ_{size} = 3.69$</li>\n</ul>\n</li>\n<li><strong>Weight (mg):</strong>\n<ul>\n<li>$μ_{weight} = (150+50+160+80+200+65) / 6 = 117.5$</li>\n<li>$σ_{weight} = 59.4$</li>\n</ul>\n</li>\n<li><strong>Wing_Span (mm):</strong>\n<ul>\n<li>$μ_{span} = (22+10+25+15+30+12) / 6 = 19.0$</li>\n<li>$σ_{span} = 7.4$</li>\n</ul>\n</li>\n</ul>\n<p><strong>Step 2: Apply the formula to each data point.</strong></p>\n<p>Let's calculate the standardized value for Sample 1 (<code>Size = 10</code>):<br>\n$x_{std} = (10 - 9.17) / 3.69 = 0.22$</p>\n<p>After doing this for every value, our dataset is transformed:</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">SampleID</th>\n<th style=\"text-align:left\">Size (std)</th>\n<th style=\"text-align:left\">Weight (std)</th>\n<th style=\"text-align:left\">Wing_Span (std)</th>\n<th style=\"text-align:left\">Type (Label)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">1</td>\n<td style=\"text-align:left\">0.22</td>\n<td style=\"text-align:left\">0.55</td>\n<td style=\"text-align:left\">0.41</td>\n<td style=\"text-align:left\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">2</td>\n<td style=\"text-align:left\">-1.13</td>\n<td style=\"text-align:left\">-1.14</td>\n<td style=\"text-align:left\">-1.22</td>\n<td style=\"text-align:left\">0</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">3</td>\n<td style=\"text-align:left\">0.77</td>\n<td style=\"text-align:left\">0.72</td>\n<td style=\"text-align:left\">0.81</td>\n<td style=\"text-align:left\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">4</td>\n<td style=\"text-align:left\">-0.59</td>\n<td style=\"text-align:left\">-0.63</td>\n<td style=\"text-align:left\">-0.54</td>\n<td style=\"text-align:left\">0</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">5</td>\n<td style=\"text-align:left\">1.58</td>\n<td style=\"text-align:left\">1.39</td>\n<td style=\"text-align:left\">1.49</td>\n<td style=\"text-align:left\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">6</td>\n<td style=\"text-align:left\">-0.86</td>\n<td style=\"text-align:left\">-0.88</td>\n<td style=\"text-align:left\">-0.95</td>\n<td style=\"text-align:left\">0</td>\n</tr>\n</tbody>\n</table>\n<p>Now all features are on the same scale, and no single feature will unfairly dominate the learning process.</p>\n<hr>\n<h3>Part 3: Evaluation Strategy - 3-Fold Cross-Validation</h3>\n<p>With our data preprocessed, how do we evaluate a model trained on it? A simple train-test split is risky with a small dataset. Instead, we'll use <strong>3-fold Cross-Validation</strong>.</p>\n<p>First, we split our 6-sample dataset into 3 &quot;folds&quot;:</p>\n<ul>\n<li><strong>Fold 1:</strong> {Sample 1, Sample 2}</li>\n<li><strong>Fold 2:</strong> {Sample 3, Sample 4}</li>\n<li><strong>Fold 3:</strong> {Sample 5, Sample 6}</li>\n</ul>\n<p>Now we perform three rounds of training and validation:</p>\n<ul>\n<li>\n<p><strong>Round 1:</strong></p>\n<ul>\n<li><strong>Train on:</strong> Folds 2 &amp; 3 ({S3, S4, S5, S6})</li>\n<li><strong>Validate on:</strong> Fold 1 ({S1, S2})</li>\n<li>Let's say our model predicts correctly, <strong>Validation Accuracy = 100%</strong>.</li>\n</ul>\n</li>\n<li>\n<p><strong>Round 2:</strong></p>\n<ul>\n<li><strong>Train on:</strong> Folds 1 &amp; 3 ({S1, S2, S5, S6})</li>\n<li><strong>Validate on:</strong> Fold 2 ({S3, S4})</li>\n<li>Let's say it predicts S3 correctly but S4 incorrectly, <strong>Validation Accuracy = 50%</strong>.</li>\n</ul>\n</li>\n<li>\n<p><strong>Round 3:</strong></p>\n<ul>\n<li><strong>Train on:</strong> Folds 1 &amp; 2 ({S1, S2, S3, S4})</li>\n<li><strong>Validate on:</strong> Fold 3 ({S5, S6})</li>\n<li>Let's say it predicts correctly, <strong>Validation Accuracy = 100%</strong>.</li>\n</ul>\n</li>\n</ul>\n<p><strong>Final Result:</strong> The cross-validated accuracy is the average of the scores from each round:<br>\n$$Final;Accuracy = \\frac{100% + 50% + 100%}{3} = 83.3%$$<br>\nThis gives us a much more reliable estimate of the model's performance than a single split.</p>\n<hr>\n<h3>Part 4: Dimensionality Reduction - Applying PCA</h3>\n<p>Our dataset has three features. For visualization and efficiency, let's see if we can reduce it to two dimensions using <strong>Principal Component Analysis (PCA)</strong>. We won't do the full matrix algebra here, but we'll walk through the conceptual steps.</p>\n<ol>\n<li>\n<p><strong>Start with Standardized Data:</strong> PCA is sensitive to scale, so this step is mandatory. We'll use our standardized table from Part 2.</p>\n</li>\n<li>\n<p><strong>Compute Covariance Matrix:</strong> We calculate a 3x3 covariance matrix that shows how the features (<code>Size</code>, <code>Weight</code>, <code>Wing_Span</code>) vary with each other. We notice that they are all highly correlated—bigger insects tend to be heavier and have larger wingspans.</p>\n</li>\n<li>\n<p><strong>Calculate Eigenvectors &amp; Eigenvalues:</strong> We find the eigenvectors and eigenvalues of the covariance matrix. The eigenvectors represent the new dimensions (the Principal Components), and the eigenvalues tell us how much variance each new dimension captures.</p>\n</li>\n<li>\n<p><strong>Select Components:</strong> Let's say the analysis gives us these (hypothetical) eigenvalues:</p>\n<ul>\n<li>Eigenvalue for PC1: <strong>2.75</strong></li>\n<li>Eigenvalue for PC2: <strong>0.20</strong></li>\n<li>Eigenvalue for PC3: <strong>0.05</strong></li>\n<li><strong>Total Variance</strong> (sum of eigenvalues) = 2.75 + 0.20 + 0.05 = 3.0</li>\n<li><strong>Variance explained by PC1:</strong> $2.75 / 3.0 = 91.7%$</li>\n<li><strong>Variance explained by PC2:</strong> $0.20 / 3.0 = 6.7%$</li>\n</ul>\n<p>Together, the first two principal components capture $91.7% + 6.7% = 98.4%$ of the total variance in the data! We can safely discard the third component.</p>\n</li>\n<li>\n<p><strong>Transform Data:</strong> We project our 3D standardized data onto the 2D subspace defined by PC1 and PC2. The result is a brand new dataset:</p>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">SampleID</th>\n<th style=\"text-align:left\">Principal Component 1</th>\n<th style=\"text-align:left\">Principal Component 2</th>\n<th style=\"text-align:left\">Type (Label)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">1</td>\n<td style=\"text-align:left\">0.65</td>\n<td style=\"text-align:left\">-0.10</td>\n<td style=\"text-align:left\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">2</td>\n<td style=\"text-align:left\">-1.82</td>\n<td style=\"text-align:left\">0.05</td>\n<td style=\"text-align:left\">0</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">3</td>\n<td style=\"text-align:left\">1.15</td>\n<td style=\"text-align:left\">-0.08</td>\n<td style=\"text-align:left\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">4</td>\n<td style=\"text-align:left\">-0.92</td>\n<td style=\"text-align:left\">0.04</td>\n<td style=\"text-align:left\">0</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">5</td>\n<td style=\"text-align:left\">2.49</td>\n<td style=\"text-align:left\">0.15</td>\n<td style=\"text-align:left\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">6</td>\n<td style=\"text-align:left\">-1.54</td>\n<td style=\"text-align:left\">-0.06</td>\n<td style=\"text-align:left\">0</td>\n</tr>\n</tbody>\n</table>\n<p>We now have a 2D dataset that is much easier to visualize and can lead to faster model training, all while retaining 98.4% of the original information.</p>\n<h3>Conclusion: Ready for Learning</h3>\n<p>We have successfully taken a raw dataset and put it through a rigorous data preparation pipeline. We:</p>\n<ol>\n<li><strong>Cleaned</strong> it by standardizing the features.</li>\n<li>Devised a <strong>robust evaluation plan</strong> with cross-validation.</li>\n<li><strong>Engineered</strong> a more efficient set of features using PCA.</li>\n</ol>\n<p>This processed data is now in the ideal state to be fed into a machine learning algorithm. We've laid the solid groundwork required to build a model that is not only accurate but also reliable and efficient. In our next session, we'll finally take this data and train a classification model.</p>\n",
      "url": "https://asquare.blog/posts/ai103.5",
      "title": "Artificial Intelligence 103.5",
      "date_modified": "2025-09-21T00:00:00.000Z",
      "author": {
        "name": "Anshuman Agrawal",
        "url": "https://asquare.blog"
      }
    },
    {
      "content_html": "<h3>Part 1: Datasets</h3>\n<p>At its heart, machine learning is about finding patterns in data. The data itself is organized into a <strong>dataset</strong>, which is typically a table of examples.</p>\n<ul>\n<li>Each row represents a <strong>sample</strong> (also called an example, instance, or data point).</li>\n<li>Each column represents a <strong>feature</strong> (also called an attribute or variable).</li>\n</ul>\n<h4>Feature Sets and Labels</h4>\n<p>A typical dataset for supervised learning is split into two parts:</p>\n<ul>\n<li><strong>Features:</strong> These are the input variables, the pieces of information we have. In a dataset to predict house prices, the features might be <code>Square_Footage</code>, <code>Num_Bedrooms</code>, and <code>Year_Built</code>. The collection of all features for a single sample is its <strong>feature set</strong> or <strong>feature vector</strong>.</li>\n<li><strong>Label:</strong> This is the output variable, the thing we are trying to predict. For the housing dataset, the label would be <code>Price</code>.</li>\n</ul>\n<p>The fundamental goal of a supervised ML model is to learn the relationship—the hidden pattern—that connects the feature set to the label.</p>\n<hr>\n<h3>Preparing Data for Learning - Preprocessing</h3>\n<p>A common saying in machine learning is <strong>&quot;Garbage in, garbage out.&quot;</strong> A sophisticated algorithm fed with poor-quality data will produce poor results. That's why a huge amount of a data scientist's time is spent on preparing and cleaning the dataset. This involves several key steps:</p>\n<ul>\n<li><strong>Handling Missing Values:</strong> Real-world datasets often have holes. A model can't handle a missing value, so we must decide on a strategy, such as filling it with the mean or median of the column (imputation) or dropping the row entirely.</li>\n<li><strong>Feature Engineering:</strong> This is the creative process of creating new, more powerful features from existing ones. For example, from <code>Num_Accidents</code> and <code>Years_Driving</code>, we could engineer a new feature called <code>Accidents_Per_Year</code>, which might be more predictive.</li>\n<li><strong>Feature Scaling:</strong> Many ML algorithms are sensitive to the scale of the features. If one feature ranges from 0-1 and another from 0-100,000, the algorithm might incorrectly assume the second feature is more important. We fix this by scaling the data, typically with one of two methods:\n<ul>\n<li><strong>Normalization (Min-Max Scaling):</strong> Rescales the data to a fixed range, usually 0 to 1. The formula for a feature value $x$ is:<br>\n$$x_{norm} = \\frac{x - x_{min}}{x_{max} - x_{min}}$$</li>\n<li><strong>Standardization (Z-score):</strong> Rescales the data to have a mean ($μ$) of 0 and a standard deviation ($σ$) of 1. The formula is:<br>\n$$x_{std} = \\frac{x - \\mu}{\\sigma}$$</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>Part 3: How a Model Generalizes - Dataset Division</h3>\n<p>Let's say we have our clean dataset. The goal is to train a model that performs well not just on the data we have, but on new, unseen data. This is the concept of <strong>generalization</strong>.</p>\n<h4>The Enemy: Overfitting</h4>\n<p>The biggest obstacle to generalization is <strong>overfitting</strong>. This happens when a model learns the training data <em>too</em> well. It memorizes not only the underlying patterns but also the noise and random fluctuations specific to that data.</p>\n<p>Think of a student who memorizes the exact questions and answers from a practice exam. They'll ace that practice test, but when they see slightly different questions on the real exam, they will fail because they never learned the underlying concepts. An overfitted model is just like that.</p>\n<h4>The Solution: Splitting the Dataset</h4>\n<p>To prevent overfitting and to properly evaluate our model, we never train on our entire dataset. We split it into three distinct sets:</p>\n<ol>\n<li><strong>Training Set (60-80%):</strong> This is the data the model actually &quot;sees&quot; and learns from. The model adjusts its internal parameters based on the patterns in this set.</li>\n<li><strong>Validation Set (10-20%):</strong> After training, we use this set to see how the model performs on data it hasn't seen before. We use this set to tune the model's <strong>hyperparameters</strong>—the external settings of the model, like its complexity or learning rate. We can tweak the model and re-evaluate on the validation set until we are happy with its performance.</li>\n<li><strong>Test Set (10-20%):</strong> This set is the final exam. We keep it locked away and only use it <em>once</em>, at the very end, after all training and tuning is complete. The performance on the test set gives us an unbiased estimate of how our model will perform in the real world on completely new data.</li>\n</ol>\n<h4>The Gold Standard: Cross-Validation</h4>\n<p>A single train-validation split can be subject to luck. Maybe we were just lucky (or unlucky) with the specific data points that ended up in our validation set. A more robust technique is <strong>k-fold Cross-Validation</strong>.</p>\n<p>Here's how it works:</p>\n<ol>\n<li>We split our data (minus the test set) into <code>k</code> equal-sized parts, or &quot;folds&quot; (e.g., 5 or 10).</li>\n<li>We perform <code>k</code> rounds of training. In each round, we use one fold as the validation set and the remaining <code>k-1</code> folds as the training set.</li>\n<li>We average the performance scores from all <code>k</code> rounds.</li>\n</ol>\n<p>This gives us a much more reliable estimate of our model's performance and reduces the impact of random chance in the split.</p>\n<hr>\n<h3>Part 4: Taming Complexity - Dimensionality Reduction</h3>\n<p>Sometimes, our datasets have too many features. While more data is often good, too many features (or dimensions) can lead to the <strong>Curse of Dimensionality</strong>. In very high-dimensional spaces, data points become sparse and far apart, making it harder for a model to find patterns. It also increases computational costs and the risk of overfitting.</p>\n<p><strong>Dimensionality Reduction</strong> techniques aim to reduce the number of features while retaining as much useful information as possible.</p>\n<h4>Principal Component Analysis (PCA)</h4>\n<p>PCA is an <strong>unsupervised</strong> technique that transforms the data into a new set of features, called <strong>principal components</strong>. It works by finding the directions of maximum <strong>variance</strong> in the data. The first principal component is the direction that captures the most variation, the second captures the next most (and is perpendicular to the first), and so on. We can then keep only the first few components, effectively reducing the dimensionality while keeping the most important information.</p>\n<p><strong>Analogy:</strong> Imagine trying to capture the essence of a 3D car model in a 2D photograph. You wouldn't take the picture from the top or bottom. You'd find the angle (like a side view) that shows the most defining features. PCA is like finding that best angle for your data.</p>\n<h4>Linear Discriminant Analysis (LDA)</h4>\n<p>LDA is a <strong>supervised</strong> technique, meaning it uses the class labels. While PCA tries to find the directions of maximum variance, LDA tries to find the directions that <strong>maximize the separability between classes</strong>. It projects the data onto a lower-dimensional space in a way that pushes different classes as far apart as possible.</p>\n<p><strong>Analogy:</strong> Imagine you have red and blue marbles scattered in a 3D box. PCA would find the axis along which the marbles are most spread out, regardless of color. LDA would find the axis that, when you look along it, shows the clearest separation between the cluster of red marbles and the cluster of blue marbles.</p>\n<h4>Independent Component Analysis (ICA)</h4>\n<p>ICA is another <strong>unsupervised</strong> technique with a different goal. It assumes that your observed features are a mixture of some underlying, independent sources. ICA tries to &quot;unmix&quot; them.</p>\n<p><strong>Analogy:</strong> This is famously known as the <strong>&quot;cocktail party problem.&quot;</strong> Imagine you are in a room with two people talking, and you have two microphones placed at different spots. Each microphone records a mixture of both voices. ICA is the algorithm that can take those two mixed recordings and separate them back into two clean recordings, one for each speaker. In data analysis, it's used to find underlying hidden factors that are statistically independent.</p>\n",
      "url": "https://asquare.blog/posts/ai103",
      "title": "Artificial Intelligence 103",
      "date_modified": "2025-09-21T00:00:00.000Z",
      "author": {
        "name": "Anshuman Agrawal",
        "url": "https://asquare.blog"
      }
    },
    {
      "content_html": "<h3>Supervised Learning: Learning with a Teacher 👨‍🏫</h3>\n<p><strong>Supervised learning</strong> is the most common and straightforward type of machine learning. The core idea is that you provide the algorithm with <strong>labeled data</strong>. This means that for every data sample, you also provide the &quot;correct answer,&quot; or label.</p>\n<p>Think of it like studying with flashcards. On one side, you have the question (the input features), and on the other, you have the answer (the output label). After seeing enough examples, you start to learn the pattern that connects the questions to the answers.</p>\n<p>Mathematically, the goal is to learn an approximate mapping function, $f$, that can map new, unseen input data ($X$) to an output label ($Y$).<br>\n$$Y \\approx f(X)$$</p>\n<p>Supervised learning is primarily used for two types of tasks: Regression and Classification.</p>\n<h4>A. Regression: Predicting Continuous Values</h4>\n<p><strong>Regression</strong> is used when the output label you're trying to predict is a continuous, numerical value. You're not predicting a category, but a quantity.</p>\n<ul>\n<li>\n<p><strong>Example Problems:</strong></p>\n<ul>\n<li>Predicting the price of a house based on its size, location, and number of bedrooms.</li>\n<li>Forecasting the temperature for tomorrow.</li>\n<li>Estimating a person's age from a photograph.</li>\n</ul>\n</li>\n<li>\n<p><strong>Types of Regression:</strong></p>\n<ul>\n<li>\n<p><strong>Linear Regression:</strong> This is the simplest form, where the model tries to fit a straight line (or a higher-dimensional plane) that best represents the data. The formula is:<br>\n$$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n + \\epsilon$$</p>\n<ul>\n<li><strong>Polynomial Regression:</strong> Used when the relationship between the features and the label isn't a straight line. The model fits a curved line to better capture the pattern.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4>B. Classification: Predicting Discrete Categories</h4>\n<p><strong>Classification</strong> is used when the output label is a discrete category. The model's job is to assign a class label to a new, unseen sample.</p>\n<ul>\n<li><strong>Example Problems:</strong>\n<ul>\n<li>Is this email <strong>spam</strong> or <strong>not spam</strong>?</li>\n<li>Does this medical image show a <strong>malignant</strong> or <strong>benign</strong> tumor?</li>\n<li>Is this handwritten digit a <strong>0, 1, 2, ... or 9</strong>?</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>Unsupervised Learning: Finding Patterns on Your Own 🕵️‍♂️</h3>\n<p>What if you don't have labeled data? That's where <strong>unsupervised learning</strong> comes in. In this case, you provide the model with a dataset that only has input features ($X$) and no corresponding labels ($Y$). The model's task is to explore the data and find meaningful structures or patterns on its own.</p>\n<p>Think of being given a box of assorted Lego bricks with no instructions. You might start grouping them by color, size, or shape. You're creating clusters of similar bricks without being told what the &quot;correct&quot; groups are.</p>\n<h4>Clustering</h4>\n<p>The most common unsupervised learning task is <strong>clustering</strong>. The goal is to group the data points in such a way that samples within the same group (or cluster) are very similar to each other, while samples in different groups are very different.</p>\n<ul>\n<li><strong>Example Problems:</strong>\n<ul>\n<li>Segmenting customers into different marketing groups based on their purchasing behavior.</li>\n<li>Grouping similar news articles together.</li>\n<li>Identifying distinct communities within a social network.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>Reinforcement Learning: Learning from Trial and Error 🤖</h3>\n<p><strong>Reinforcement Learning (RL)</strong> is a completely different paradigm. It's not about learning from a static dataset but about an <strong>agent</strong> learning to behave in an <strong>environment</strong>. The agent learns by taking <strong>actions</strong> and receiving <strong>rewards</strong> or <strong>penalties</strong> as feedback.</p>\n<p>The goal of the agent is to learn a strategy, or <strong>policy</strong>, that maximizes its total reward over time.</p>\n<ul>\n<li><strong>Analogy:</strong> This is exactly how you train a pet. You command your dog to &quot;sit.&quot; If it sits, you give it a treat (a positive reward). If it walks away, it gets nothing. Over time, the dog learns the policy: the action &quot;sit&quot; in the state &quot;hearing the 'sit' command&quot; leads to a reward.</li>\n</ul>\n<ul>\n<li><strong>Example Problems:</strong>\n<ul>\n<li>Training an AI to play a game like chess, Go, or a video game. The reward is winning the game or achieving a high score.</li>\n<li>Teaching a robot how to walk. The reward could be for moving forward without falling.</li>\n<li>Optimizing the energy consumption of a data center.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3>Semi-supervised Machine Learning: A Hybrid Approach 🤝</h3>\n<p><strong>Semi-supervised learning</strong> is a bridge between supervised and unsupervised learning. It's used for situations where you have a small amount of <strong>labeled data</strong> and a vast amount of <strong>unlabeled data</strong>. This scenario is very common because labeling data can be expensive and time-consuming.</p>\n<p>The model uses the unlabeled data to first learn the general structure and patterns of the data (like in unsupervised learning). Then, it uses the small amount of labeled data to refine its understanding and attach meaning to those patterns.</p>\n<ul>\n<li><strong>Example Problem:</strong>\n<ul>\n<li>A service like Google Photos has billions of unlabeled user photos. When you manually tag your friend &quot;John&quot; in a few pictures (providing a small amount of labeled data), the service can use the patterns it has learned from all photos to find every other picture of John in your library.</li>\n</ul>\n</li>\n</ul>\n",
      "url": "https://asquare.blog/posts/ai104",
      "title": "Artificial Intelligence 104.5",
      "date_modified": "2025-09-21T00:00:00.000Z",
      "author": {
        "name": "Anshuman Agrawal",
        "url": "https://asquare.blog"
      }
    },
    {
      "content_html": "<h2>AI for Society</h2>\n<p>AI is being deployed as a force for good, with a particular focus on empowering vulnerable communities and protecting our planet.</p>\n<h3>AI for Women</h3>\n<ul>\n<li><strong>Healthcare:</strong> AI is making significant strides in women's health. Machine learning models can analyze mammograms and Pap smear slides to detect signs of breast and cervical cancer, often with higher accuracy and at earlier stages than human specialists. AI also powers personalized medicine, tailoring treatments for conditions like endometriosis or polycystic ovary syndrome (PCOS) based on an individual's unique data.</li>\n<li><strong>Safety:</strong> AI-powered systems enhance safety for women in public and private spaces. This includes smart city surveillance that can automatically detect signs of distress or aggression, mobile apps that can send real-time alerts to emergency contacts, and sophisticated algorithms that work to identify and filter out online harassment and abuse on social media platforms.</li>\n<li><strong>Economic Empowerment:</strong> By analyzing job market data, AI can provide women with personalized career coaching and recommendations for upskilling. In hiring, AI tools are being developed to identify and mitigate unconscious bias in job descriptions and resume screening, helping to level the playing field for female candidates.</li>\n</ul>\n<h3>AI for the Environment 🌍</h3>\n<ul>\n<li><strong>Climate Modeling:</strong> AI can process petabytes of satellite data, ocean sensor readings, and atmospheric measurements to build highly accurate models of Earth's climate. These models help scientists predict the impact of climate change with greater confidence and simulate the potential effects of different environmental policies.</li>\n<li><strong>Biodiversity Conservation:</strong> Drones equipped with AI-powered computer vision can monitor vast, remote areas to track endangered species populations, identify signs of illegal deforestation, and detect poachers in real-time. This allows conservation teams to respond more quickly and effectively.</li>\n<li><strong>Energy Optimization:</strong> AI is the brain behind the &quot;smart grid.&quot; By forecasting energy demand based on weather, time of day, and historical usage, AI helps utility companies reduce waste, prevent outages, and seamlessly integrate fluctuating renewable energy sources like wind and solar power into the national grid.</li>\n<li><strong>Sustainable Agriculture:</strong> Known as <strong>precision agriculture</strong>, AI provides farmers with actionable insights. By analyzing data from drones, soil sensors, and weather stations, AI can tell a farmer exactly which crops need water, fertilizer, or pesticides, optimizing resource use, reducing environmental runoff, and increasing crop yields.</li>\n</ul>\n<hr>\n<h2>Applications of Machine Learning Across Industries</h2>\n<p>AI and ML are no longer futuristic concepts; they are the operational backbone of modern industry.</p>\n<h3>Banking 🏦</h3>\n<ul>\n<li><strong>Fraud Detection:</strong> ML algorithms are the unsung heroes of financial security. They analyze millions of transactions per second, learning the normal spending patterns for each customer. When a transaction deviates from this pattern—like a purchase in a new country just minutes after a local one—the system flags it as potentially fraudulent in real-time.</li>\n<li><strong>Credit Scoring:</strong> Instead of relying on a few traditional data points, ML models can analyze thousands of variables to create a much more nuanced and accurate assessment of a person's creditworthiness, enabling fairer access to loans.</li>\n</ul>\n<h3>Security 🛡️</h3>\n<ul>\n<li><strong>Cybersecurity:</strong> AI is a crucial defense against cyberattacks. It learns the baseline behavior of a computer network and can instantly detect anomalies that might signal a malware infection or an unauthorized intrusion. It's also the technology behind modern spam filters that automatically classify and block billions of phishing attempts daily.</li>\n<li><strong>Biometric Security:</strong> The face, fingerprint, or voice recognition you use to unlock your phone is powered by machine learning models trained on vast datasets to recognize unique biological patterns.</li>\n</ul>\n<h3>Healthcare 🩺</h3>\n<ul>\n<li><strong>Medical Imaging:</strong> Deep learning models, particularly Convolutional Neural Networks (CNNs), are now capable of analyzing medical scans like X-rays, MRIs, and retinal scans to detect diseases such as pneumonia, brain tumors, and diabetic retinopathy with expert-level accuracy.</li>\n<li><strong>Drug Discovery:</strong> Developing a new drug can take over a decade and cost billions. AI accelerates this process by predicting how different molecules will behave and identifying promising candidates for new drugs, drastically cutting down research and development time.</li>\n</ul>\n<h3>Education 🎓</h3>\n<ul>\n<li><strong>Personalized Learning:</strong> AI-driven educational platforms can adapt to each student's individual learning pace. If a student is struggling with a concept, the system can provide additional resources and practice problems. If they've mastered a topic, it can move them ahead.</li>\n<li><strong>Automated Grading:</strong> AI can automate the grading of multiple-choice tests and even some forms of written assessment, freeing up teachers' time from administrative tasks so they can focus on teaching and mentoring students.</li>\n</ul>\n<h3>Insurance Industry 📄</h3>\n<ul>\n<li><strong>Risk Assessment:</strong> AI has transformed underwriting. To set a car insurance premium, an ML model can analyze not just a person's driving record but also data from telematics devices in their car to assess their actual driving behavior (like hard braking or speeding), leading to fairer and more accurate pricing.</li>\n<li><strong>Automated Claims Processing:</strong> When a car is in an accident, a user can upload photos of the damage. An AI model can then instantly assess the extent of the damage, estimate the repair cost, and in many cases, approve the claim automatically within minutes.</li>\n</ul>\n<h3>Retail and Supply Chain 🛍️</h3>\n<ul>\n<li><strong>Recommendation Engines:</strong> The product and movie recommendations you see on sites like Amazon and Netflix are powered by ML. These systems analyze your past behavior and compare it to millions of other users to predict what you might like next.</li>\n<li><strong>Demand Forecasting:</strong> Retailers use ML to predict how much of a product will be needed in a specific store at a specific time. This helps prevent items from going out of stock and reduces waste from overstocking, especially for perishable goods.</li>\n</ul>\n<h3>Transportation and Logistics 🚚</h3>\n<ul>\n<li><strong>Route Optimization:</strong> Services like Google Maps use ML to analyze real-time traffic conditions, road closures, and speed limits to calculate the most efficient route for your journey, saving millions of hours of travel time collectively every day.</li>\n<li><strong>Predictive Maintenance:</strong> AI systems monitor data from sensors on trucks, trains, and airplanes to predict when a part is likely to fail. This allows for maintenance to be scheduled <em>before</em> a breakdown occurs, increasing safety and reliability.</li>\n</ul>\n<h3>Energy and Utilities ⚡</h3>\n<ul>\n<li><strong>Infrastructure Monitoring:</strong> Instead of manually inspecting thousands of miles of pipelines or power lines, utility companies use drones and AI to analyze the footage for signs of damage, corrosion, or vegetation encroachment, making maintenance safer and more proactive.</li>\n<li><strong>Energy Theft Detection:</strong> By analyzing smart meter data, ML models can identify consumption patterns that are inconsistent with normal usage, flagging potential instances of illegal energy theft and saving utility companies millions.</li>\n</ul>\n",
      "url": "https://asquare.blog/posts/ai105",
      "title": "Artificial Intelligence 105",
      "date_modified": "2025-09-21T00:00:00.000Z",
      "author": {
        "name": "Anshuman Agrawal",
        "url": "https://asquare.blog"
      }
    },
    {
      "content_html": "<p><a href=\"https://drive.google.com/drive/folders/11qQGgTfeZBZQbaNqmk63vYE8OkD-vCao?usp=share_link\">Cheatsheet</a></p>\n",
      "url": "https://asquare.blog/posts/python_cheatsheet",
      "title": "Essential Python Library Cheatsheet",
      "date_modified": "2025-09-07T00:00:00.000Z",
      "author": {
        "name": "Anshuman Agrawal",
        "url": "https://asquare.blog"
      }
    },
    {
      "content_html": "<p>We live most of our lives half-asleep to the obvious. Not because we’re dumb, but because remembering these truths all the time would probably make us combust. So here’s a little reminder of the properties that sit in the background, the ones we forget, ignore, or try to deny.</p>\n<hr>\n<h3>Contradiction is natural</h3>\n<p>We act like contradictions mean hypocrisy. They don’t. They mean <em>human</em>. Wanting to grind but also rest. Wanting solitude but also love. The clash itself is the system working. To write this list is already a contradiction — trying to pin down what by nature refuses to be pinned.</p>\n<hr>\n<h3>The body thinks too</h3>\n<p>Brains get all the spotlight, but muscles, gut, and breath are doing half the heavy lifting. Your stomach has a nervous system of its own. Your posture changes your mood. A run can solve a problem your “rational” brain couldn’t. The body isn’t just hardware. It’s co-author.</p>\n<hr>\n<h3>Forgetting is functional</h3>\n<p>We treat forgetting as a bug. It’s not. It’s the cleanup crew. The brain burns the junk to make space. Sometimes it torches something we swore was important — and that hurts. But forgetting is the price of moving forward. Memory is selective for a reason.</p>\n<hr>\n<h3>Obsession is a feature</h3>\n<p>Call it obsession, tunnel vision, mania. It’s how we actually learn. Nobody ever mastered anything by staying “balanced” all the time. Falling into the rabbit hole is not dysfunction — it’s how mastery is carved.</p>\n<hr>\n<h3>The self is fluid</h3>\n<p>We cling to identities like they’re bedrock. They’re not. Self is clay. You are not one story. You are drafts upon drafts, edits upon edits. Reinvention is baked into the design.</p>\n<hr>\n<h3>Rest is not laziness</h3>\n<p>Stillness is not a sin. Naps are not moral failure. Boredom is not wasted time. These are maintenance cycles — like turning the system off to cool the circuits. Ignore this and you don’t become more productive, you just break.</p>\n<hr>\n<h3>The social need</h3>\n<p>Even the lone wolves crave an echo. We tell ourselves we don’t need others, but mirrors are built into us. Recognition, witness, connection — these aren’t “nice to haves.” They’re survival.</p>\n<hr>\n<p>We forget these things because we want to be gods of control. Instead, we’re messy paradox machines, bodies that think, minds that forget, selves that bend. Maybe remembering that is enough.</p>\n<hr>\n",
      "url": "https://asquare.blog/posts/wishful_thinking",
      "title": "A list of things we forget about us",
      "date_modified": "2025-08-10T00:00:00.000Z",
      "author": {
        "name": "Anshuman Agrawal",
        "url": "https://asquare.blog"
      }
    },
    {
      "content_html": "<p>Have you ever noticed how your perception of yourself changes depending on who surrounds you or what you're doing? One minute, you're energized, inspired, and feeling genuinely fulfilled. The next, you're drained, irritable, and questioning your worth.</p>\n<p>I recently found clarity on this issue while reading David Deutsch's &quot;The Beginning of Infinity.&quot; Deutsch contrasts how ordinary people perceive the universe—limited by immediate surroundings—with how astronauts envision the vast, limitless cosmos. This simple yet profound distinction ignited a powerful realization in me:</p>\n<p>&quot;I hate myself when I'm surrounded by uninteresting, uninspiring people.&quot;</p>\n<p>&quot;I like myself when I'm intellectual, romanticizing life, and immersed in learning.&quot;</p>\n<p>So why do we spend so much of our precious time in situations that make us dislike ourselves? Why don't we intentionally choose environments that amplify our self-love and sense of identity?</p>\n<p>Here's what I've discovered:</p>\n<h3>1. Recognize What Makes You Love Yourself</h3>\n<p>Identify the activities, people, and environments that genuinely make you feel alive. For me, it's reading fascinating books, contemplating big ideas, playing music, experimenting with digital art, and embracing my inner nerd. These aren't just hobbies; they're foundational pillars of my identity.</p>\n<h3>2. Curate Your Environment Consciously</h3>\n<p>If your surroundings shape your identity, then curating them becomes an essential act of self-care. Distance yourself from environments and interactions that drain your energy and self-esteem. Seek connections with people who fuel your intellectual curiosity and emotional growth.</p>\n<h3>3. Align Your Actions with Your Identity</h3>\n<p>Taking consistent action in alignment with who you truly believe yourself to be builds self-respect. When you live authentically—when your actions echo your identity—self-love naturally deepens. The inner conflict dissolves because you're no longer pretending or compromising your core self.</p>\n<h3>4. Embrace Romanticizing Life</h3>\n<p>Romanticizing life isn't about ignoring reality. It's about finding beauty and inspiration in the mundane, approaching life with curiosity, wonder, and passion. This perspective enhances your self-image because it nurtures a narrative where you're actively creating meaning.</p>\n<h3>5. Guard Your Identity Fiercely</h3>\n<p>Protecting your sense of self from external negativity is crucial. Remember that the version of you who thrives intellectually, artistically, and spiritually deserves the utmost care. Shield this precious identity from dilution by superficial, unfulfilling engagements.</p>\n<p>By knowing yourself intimately and acting accordingly, you create a life where self-hate has no room to thrive. You're actively nurturing an identity that resonates deeply with your beliefs, passions, and aspirations. Ultimately, self-love flourishes not because you've become perfect, but because you've become authentic.</p>\n<p>In a vast universe of infinite possibilities, choosing to love yourself means choosing the path that brings you closest to your true essence. And isn't that the most important journey of all?</p>\n",
      "url": "https://asquare.blog/posts/self_love_01",
      "title": "How not to hate yourself",
      "date_modified": "2025-08-06T00:00:00.000Z",
      "author": {
        "name": "Anshuman Agrawal",
        "url": "https://asquare.blog"
      }
    },
    {
      "content_html": "<p>Some days the noise outside is deafening. Not just audible sounds—traffic, chatter, a barking dog—but the overwhelming chaos of living in a world constantly screaming for your attention. Notifications, ads, expectations, noise layered on noise, each more urgent than the last.</p>\n<p>You wake with purpose—a plan laid out, clear, simple. Yet, before your feet touch the floor, the external chaos floods in, blurring the edges, pulling your mind in a thousand meaningless directions.</p>\n<p>That's outer noise—easy to blame, easy to identify. But beneath that obvious chaos lies something more sinister, more subtle:</p>\n<p><strong>Inner resistance.</strong></p>\n<p>It doesn't shout—it whispers. Gentle, persuasive:</p>\n<p>&quot;Maybe you're too tired today.&quot;<br>\n&quot;You deserve a break.&quot;<br>\n&quot;You might fail anyway.&quot;<br>\n&quot;Tomorrow would be better.&quot;</p>\n<p>This resistance is cunning. It pretends to be your ally, offering comfort, safety, escape. It weaponizes logic, feeds you half-truths, and watches silently as ambition slips through your fingers like sand.</p>\n<p>The truth no one shares enough: <strong>Starting is painful.</strong></p>\n<p>Not because the work itself is inherently difficult—though often it is—but because it requires passing through your own invisible barriers, breaking your comfortable illusions, shattering the cocoon of procrastination.</p>\n<p>Because real focus isn’t pretty or effortless. It's a messy battle, gritty, exhausting, relentless. You don’t gracefully glide into deep work; you claw your way there, inch by painful inch, fighting every impulse that begs for distraction.</p>\n<p>But here’s the strange beauty of relentless focus: <strong>eventually, if you fight long enough, you break through.</strong></p>\n<p>The noise doesn’t disappear—it becomes irrelevant. The resistance doesn't vanish—it loses power. You're simply there, quietly working, calmly ruthless, beyond doubt, beyond comfort, beyond the need for immediate reward.</p>\n<p>In that quiet, in that rare intensity, there's clarity unlike anything else. The heart rate slows, thoughts sharpen. You become singular—one purpose, one task, one moment unfolding into the next.</p>\n<p>This is calm hard work—not tranquil meditation, but disciplined rebellion. Silent, fierce, precise. No applause, no validation, no distractions.</p>\n<p>Just you, wrestling with meaning.<br>\nJust you, battling noise.<br>\nJust you, creating something real.</p>\n<p>And when you reach that place, it isn’t victory over the world—it’s victory over yourself.</p>\n<p>In a culture obsessed with shortcuts and dopamine hits, choose the harder path:</p>\n<p><strong>Sit down, quiet the noise, confront the resistance, and build something with intense, unflinching focus.</strong></p>\n<p>That’s the quiet war worth fighting.</p>\n",
      "url": "https://asquare.blog/posts/quiet_war_of_focus",
      "title": "Quiet War of Focus",
      "date_modified": "2025-08-05T00:00:00.000Z",
      "author": {
        "name": "Anshuman Agrawal",
        "url": "https://asquare.blog"
      }
    },
    {
      "content_html": "<p>Maybe I’m human. Or maybe I’m just a shadow pretending to be one. Carbon atoms, water, neurons—star dust that got lucky. Lucky enough to somehow… notice itself.<br>\nSelf-awareness. That grand illusion. That voice in my head saying <em>I am</em>. But is it real? Or just another line of code in a program that was designed to say <em>I am</em>?</p>\n<p>If a machine said “I feel,” would we believe it?<br>\nIf I stop feeling, stop questioning, stop watching myself—do I stop being human?<br>\nIs <em>being human</em> just about having this recursive loop of <em>“I know that I know that I exist”</em>?</p>\n<p>Or maybe I’m not even here.<br>\nMaybe I’m someone else's hallucination.<br>\nMaybe I’m a butterfly dreaming of a boy.<br>\nOr a dream inside an android’s hard-coded subconscious.<br>\nWait—can androids even dream?<br>\nWhat <em>is</em> a dream anyway?<br>\nA glitch in memory? A story stitched by a sleeping brain?<br>\nAn echo of something I wanted but couldn’t say?</p>\n<p>Maybe I’m not real.<br>\nMaybe none of this is.<br>\nMaybe we’re just a tape, a sequence of frames running in a simulation nested within a simulation, three layers deep, projected for the idle amusement of some fourth-dimensional beings munching on alien popcorn.<br>\nMaybe they’re laughing at this paragraph right now.<br>\nMaybe this question is a feature.<br>\nMaybe it’s a bug.</p>\n<p>But does it matter?</p>\n<p>If I’m a dream, then it’s a vivid one.<br>\nIf I’m a lie, it’s a damn beautiful lie.<br>\nIf none of this is real, then pain still hurts, music still moves me, and silence still feels holy.<br>\nSo maybe <em>being real</em> isn’t the point.<br>\nMaybe <em>feeling real</em> is.</p>\n<p>Maybe I don't need an answer.<br>\nMaybe I just need to keep asking.</p>\n<p>Who am I?</p>\n",
      "url": "https://asquare.blog/posts/who_am_i",
      "title": "Who am I?",
      "date_modified": "2025-08-03T00:00:00.000Z",
      "author": {
        "name": "Anshuman Agrawal",
        "url": "https://asquare.blog"
      }
    },
    {
      "content_html": "<p><a href=\"https://patrickcollison.com/advice\">https://patrickcollison.com/advice</a></p>\n",
      "url": "https://asquare.blog/posts/advice",
      "title": "Some useful advice",
      "summary": "advice",
      "date_modified": "2025-08-02T00:00:00.000Z",
      "author": {
        "name": "Anshuman Agrawal",
        "url": "https://asquare.blog"
      }
    },
    {
      "content_html": "<p>This might be the single most important question you could tackle early in life. First off, let’s accept there is always an answer—even if it feels elusive. But why does this question matter so much? Sure, there are other profound questions like, “What is life?” or “What is the meaning of life?” or even “Why are we here?” But imagine we actually got an answer: say life is a simulation, and your entire purpose is to eat apples. Even if that were true, would you choose to do nothing but eat apples? Probably not. So maybe the answers to those questions aren't as crucial as we think. What really matters, perhaps, is figuring out how to live your life well. But here’s another snag—what exactly is a &quot;good&quot; life? With endless hedonistic pleasures available, defining a good life becomes incredibly complicated. Most people default to happiness as a metric, but if the point isn't solely happiness, then what? Suffering certainly isn't it—that would be too harsh and meaningless. You see the problem? Maybe a better question is: what makes a life truly worth living? For some, it’s family; for others, it's relationships, personal achievements, or finding balance. Everyone has a different perspective.</p>\n<p>Let’s try approaching this logically:</p>\n<p>If we're defining the &quot;worth&quot; of life, we're assuming life is something measurable. But how do we measure life? Duration? Quality? Both seem inadequate on their own. Logically, value must consider subjective factors (personal happiness, satisfaction, fulfillment) and objective factors (health, productivity, societal contribution). Given the complexity of human experience, subjective perceptions naturally become central—your internal perception fundamentally shapes how worthwhile you feel your life is.</p>\n<p>People generally value coherence and consistency between their beliefs and actions—this alignment brings psychological comfort and clarity. If your actions contradict your beliefs, discomfort follows, eroding your life's perceived worth. So logically, coherence between who you are and what you do is vital.</p>\n<p>Next, consider meaning. Meaning is essential because it stitches life's disparate events into a cohesive narrative. Without meaning, life fragments into disconnected, confusing episodes. Logically, a clear purpose provides direction, turning experiences into coherent, meaningful parts of your personal narrative.</p>\n<p>Another critical piece is fulfillment. Humans naturally seek fulfillment through achieving goals and personal growth. Logically, fulfillment emerges as you set, pursue, and achieve meaningful objectives. Overcoming challenges provides lasting satisfaction, logically enhancing the perceived value of life.</p>\n<p>Relationships also logically elevate life's worth. Humans, being inherently social, derive immense value from authentic connections. These genuine relationships—marked by trust, empathy, and mutual growth—dramatically improve life's perceived quality and depth.</p>\n<p>Contributions matter too. Making a positive impact, whether on others or society, logically adds significant value. Knowing your existence improves lives or advances society gives profound meaning and worth to your life.</p>\n<p>Authenticity logically matters because inauthenticity generates internal conflict. Aligning your external actions with your internal identity resolves psychological tension, logically enhancing your emotional health and overall life satisfaction.</p>\n<p>Lastly, resilience logically addresses life's unpredictability. Life inevitably includes adversity, and resilience—the ability to effectively adapt to difficult conditions—ensures challenges become opportunities for growth, logically increasing life's value.</p>\n<p>Ultimately, examining life logically shows us that coherence, meaningful purpose, fulfillment, authentic relationships, contributions, authenticity, and resilience collectively define what makes a life genuinely worth living.</p>\n",
      "url": "https://asquare.blog/posts/life_worth_living",
      "title": "Life worth living",
      "date_modified": "2025-08-01T00:00:00.000Z",
      "author": {
        "name": "Anshuman Agrawal",
        "url": "https://asquare.blog"
      }
    }
  ]
}
